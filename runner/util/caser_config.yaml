datasets:
  test:
    dataset:
      csv_file: /Users/nosebrain/Desktop/small/test.csv
      csv_file_index: /Users/nosebrain/Desktop/small/test.idx
      delimiter: "\t"
      item_column_name: item_id
      nip_index_file: /Users/nosebrain/Desktop/small/test.nip.idx
    loader:
      batch_size: 4
      max_seq_length: 10
  train:
    dataset:
      csv_file: /Users/nosebrain/Desktop/small/train.csv
      csv_file_index: /Users/nosebrain/Desktop/small/train.idx
      delimiter: "\t"
      item_column_name: item_id
    loader:
      batch_size: 4
      max_seq_length: 10
  validation:
    dataset:
      csv_file: /Users/nosebrain/Desktop/small/valid.csv
      csv_file_index: /Users/nosebrain/Desktop/small/valid.idx
      delimiter: "\t"
      item_column_name: item_id
      nip_index_file: /Users/nosebrain/Desktop/small/valid.nip.idx
    loader:
      batch_size: 4
      max_seq_length: 10
model:
  dropout: 0.1
  item_vocab_size: 249
  user_vocab_size: 0
  max_seq_length: 10
  embedding_size: 16
  num_vertical_filters: 5
  num_horizontal_filters: 2
  fc_activation_fn: relu
  conv_activation_fn: relu
module:
  learning_rate: 0.001
  weight_decay: 0.01
  metrics:
    ids:
      - recall
      - mrr
    k:
      - 1
      - 3
      - 5
      - 10
tokenizer:
  special_tokens:
    pad_token: <PAD>
  vocabulary:
    delimiter: "\t"
    file: /Users/nosebrain/Desktop/small/items.vocab
trainer:
  checkpoints:
    monitor: recall_at_5
    save_top_k: 3
  default_root_dir: /tmp/checkpoints
  gradient_clip_val: 0.5
  limit_train_batches: 10
  limit_val_batches: 10
