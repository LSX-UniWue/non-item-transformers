datamodule:
  dataset: "example"
  data_sources:
    num_workers: 4
    batch_size: 2
    max_seq_length: 7
    #mask_probability: 0.2
    #mask_seed: 42
    split: "ratio_split"
    file_prefix: "example"
    train:
      type: "session"
      processors:
        - type: "input_dictionaries"
        - type: "target_extractor"
          parallel: true
    validation:
      type: "session"
      processors:
        - type: "input_dictionaries"
        - type: "target_extractor"
    test:
      type: "session"
      processors:
        - type: "input_dictionaries"
        - type: "target_extractor"
  preprocessing:
    input_file_path: "/Users/lisa/recommender/tests/example_dataset_plp/example.csv"
    output_directory: "/Users/lisa/recommender/tests/example_dataset_plp"
templates:
  unified_output:
    path: "/Users/lisa/recommender/tmp/example/kebert4rec"
module:
  type: "non-items-sasrec-cross"
  loss_category: "attr_one"
  loss_category_epochs: 1
  loss_factor: 0.5
  item_type_id:  "item_id_type"
  metrics:
    full:
      metrics:
        mrr: [1, 5, 10]
        recall: [1, 5, 10]
        ndcg: [1, 5, 10]
  model:
    max_seq_length: 7
    num_transformer_heads: 1
    num_transformer_layers: 1
    transformer_hidden_size: 4
    transformer_dropout: 0.2
    loss_category: "attr_one"
    item_id_type_settings:
      name: "item_id_type"
      extra_embbedding: true
      merge: "add"
    sequence_attributes:
      prepend:
        attr_one:
          embedding: "keys"
          embedding_type: 'linear_upscale'
    item_attributes:
      prefusion:
        item_map:
          embedding: "vector"
          embedding_type: 'linear_upscale'
          merge_function: "add"
      postfusion:
        item_map:
          embedding: "vector"
          embedding_type: 'linear_upscale'
          merge_function: "multiply"
features:
  item:
    column_name: "item_id"
    sequence_length: 7
    tokenizer:
      special_tokens:
        pad_token: "<PAD>"
        mask_token: "<MASK>"
        unk_token: "<UNK>"
      vocabulary:
  np_cat:
    column_name: "np_cat"
    sequence_length: 7
    tokenizer:
      special_tokens:
        pad_token: "<PAD>"
        mask_token: "<MASK>"
        unk_token: "<UNK>"
      vocabulary:
  item_id_type:
    column_name: "item_id_type"
    sequence_length: 7
    type: "int"
    run_tokenization: false
    special_values:
      pad_value: "0"
      mask_value: "0"
      unk_value: "0"
  item_map:
    column_name: "item_id"
    sequence_length: 7
    max_sequence_step_length: 2
    run_tokenization: false
    dictionary:
      type: "pd.array"
      element_type: "float"
      dict_path: "/Users/lisa/recommender/example_data/image_vectors.csv"
      delimiter: ","
      pad_value: "[0.1,0.1]"
      mask_value: "[0.1,0.1]"
      unk_value: "[0.1,0.1]"
  attr_one:
    column_name: "attr_one"
    sequence_length: 7
    type: "list"
    delimiter: "|"
    element_type: "str"
    max_sequence_step_length: 2
    tokenizer:
      special_tokens:
        pad_token: "<PAD>"
        mask_token: "<MASK>"
        unk_token: "<UNK>"
trainer:
  loggers:
    tensorboard:
    mlflow:
  checkpoint:
    monitor: "recall@10"
    save_top_k: 3
    mode: 'max'
  early_stopping:
    min_delta: 0.001
    mode: "max"
    monitor: "recall@10"
    patience: 100
  gpus: 0
  max_epochs: 5
  check_val_every_n_epoch: 1
evaluation:
  evaluators:
      - type: "sid"
        use_session_id: false
      - type: "recommendation"
      - type: "metrics"
      - type: "input"
      - type: "scores"
      - type: "target"
  #filter_items:
  #  file: "/Users/lisa/recommender/configs/selected_items.csv"
  number_predictions: 5
  writer:
    type: "csv-single-line"
